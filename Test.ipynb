{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/twcs.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(df.info())\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "MoeJ8Wzx8eH3",
        "outputId": "c65bc771-16a5-482e-8f89-98e7e441ca2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 59565 entries, 0 to 59564\n",
            "Data columns (total 7 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   tweet_id                 59565 non-null  int64  \n",
            " 1   author_id                59565 non-null  object \n",
            " 2   inbound                  59565 non-null  bool   \n",
            " 3   created_at               59565 non-null  object \n",
            " 4   text                     59564 non-null  object \n",
            " 5   response_tweet_id        40156 non-null  object \n",
            " 6   in_response_to_tweet_id  44324 non-null  float64\n",
            "dtypes: bool(1), float64(1), int64(1), object(4)\n",
            "memory usage: 2.8+ MB\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   tweet_id   author_id  inbound                      created_at  \\\n",
              "0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
              "1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
              "2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
              "3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
              "4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
              "\n",
              "                                                text response_tweet_id  \\\n",
              "0  @115712 I understand. I would like to assist y...                 2   \n",
              "1      @sprintcare and how do you propose we do that               NaN   \n",
              "2  @sprintcare I have sent several private messag...                 1   \n",
              "3  @115712 Please send us a Private Message so th...                 3   \n",
              "4                                 @sprintcare I did.                 4   \n",
              "\n",
              "   in_response_to_tweet_id  \n",
              "0                      3.0  \n",
              "1                      1.0  \n",
              "2                      4.0  \n",
              "3                      5.0  \n",
              "4                      6.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1eef0777-d090-4d94-9832-dbeed664c2a0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>author_id</th>\n",
              "      <th>inbound</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>response_tweet_id</th>\n",
              "      <th>in_response_to_tweet_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
              "      <td>@115712 I understand. I would like to assist y...</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
              "      <td>@sprintcare and how do you propose we do that</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
              "      <td>@sprintcare I have sent several private messag...</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>sprintcare</td>\n",
              "      <td>False</td>\n",
              "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
              "      <td>@115712 Please send us a Private Message so th...</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>115712</td>\n",
              "      <td>True</td>\n",
              "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
              "      <td>@sprintcare I did.</td>\n",
              "      <td>4</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1eef0777-d090-4d94-9832-dbeed664c2a0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1eef0777-d090-4d94-9832-dbeed664c2a0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1eef0777-d090-4d94-9832-dbeed664c2a0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-07db30e4-8b0e-4f71-9b32-4752a2618cd3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-07db30e4-8b0e-4f71-9b32-4752a2618cd3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-07db30e4-8b0e-4f71-9b32-4752a2618cd3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 59565,\n  \"fields\": [\n    {\n      \"column\": \"tweet_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21057,\n        \"min\": 1,\n        \"max\": 74741,\n        \"num_unique_values\": 59565,\n        \"samples\": [\n          28673,\n          38241,\n          298\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"author_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16376,\n        \"samples\": [\n          \"117437\",\n          \"131685\",\n          \"120113\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"inbound\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"created_at\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49911,\n        \"samples\": [\n          \"Sun Nov 26 00:56:48 +0000 2017\",\n          \"Wed Nov 01 19:18:32 +0000 2017\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 59344,\n        \"samples\": [\n          \"@120661 Hi Marcus. Can you send us a clear picture of the product please? Corey\",\n          \"@Delta Yes, that\\u2019s the one\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response_tweet_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40156,\n        \"samples\": [\n          \"35394\",\n          \"58708\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"in_response_to_tweet_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21083.16538955772,\n        \"min\": 1.0,\n        \"max\": 74740.0,\n        \"num_unique_values\": 40222,\n        \"samples\": [\n          12681.0,\n          43351.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "file_path = \"/content/twcs.csv\"\n",
        "df = pd.read_csv(\"/content/twcs.csv\")\n",
        "\n",
        "print(df.info())\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\W', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "df['cleaned_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "# Keyword-based categorization\n",
        "def categorize_query(text):\n",
        "    if any(word in text for word in ['order', 'shipment', 'tracking']):\n",
        "        return 'order_status'\n",
        "    elif any(word in text for word in ['return', 'refund', 'cancel']):\n",
        "        return 'returns'\n",
        "    elif any(word in text for word in ['price', 'availability', 'product']):\n",
        "        return 'product_info'\n",
        "    elif any(word in text for word in ['error', 'issue', 'support']):\n",
        "        return 'technical_support'\n",
        "    else:\n",
        "        return 'general_inquiry'\n",
        "\n",
        "# Apply categorization\n",
        "df['category'] = df['cleaned_text'].apply(categorize_query)\n",
        "\n",
        "# Display category distribution\n",
        "print(\"\\nCategory Distribution:\")\n",
        "print(df['category'].value_counts())\n",
        "\n",
        "# Save categorized data for classification\n",
        "df[['text', 'cleaned_text', 'category']].to_csv('/mnt/data/categorized_queries.csv', index=False)\n",
        "print(\"\\nCategorized data saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "e-J3avW08k2-",
        "outputId": "23ac6913-86af-482a-ac86-63e5e817d668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2811774 entries, 0 to 2811773\n",
            "Data columns (total 7 columns):\n",
            " #   Column                   Dtype  \n",
            "---  ------                   -----  \n",
            " 0   tweet_id                 int64  \n",
            " 1   author_id                object \n",
            " 2   inbound                  bool   \n",
            " 3   created_at               object \n",
            " 4   text                     object \n",
            " 5   response_tweet_id        object \n",
            " 6   in_response_to_tweet_id  float64\n",
            "dtypes: bool(1), float64(1), int64(1), object(4)\n",
            "memory usage: 131.4+ MB\n",
            "None\n",
            "\n",
            "Category Distribution:\n",
            "category\n",
            "general_inquiry      2137468\n",
            "technical_support     425473\n",
            "order_status          128821\n",
            "returns                82888\n",
            "product_info           37124\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Cannot save file into a non-existent directory: '/mnt/data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-96088785639b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Save categorized data for classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cleaned_text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mnt/data/categorized_queries.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nCategorized data saved successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 )\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3965\u001b[0m         )\n\u001b[1;32m   3966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3967\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3968\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         )\n\u001b[0;32m-> 1014\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \"\"\"\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0;31m# Only for write methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/mnt/data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset with error handling\n",
        "file_path = \"/content/twcs.csv\"\n",
        "\n",
        "# Use encoding and error handling parameters\n",
        "try:\n",
        "    df = pd.read_csv(file_path, encoding='utf-8', on_bad_lines='skip', quoting=3)\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "    print(df.info())\n",
        "except Exception as e:\n",
        "    print(f\"Error loading the dataset: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBlA10s194EG",
        "outputId": "1c9e010b-3420-40eb-b3f6-8fed943eca9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-bd227c460ce5>:8: DtypeWarning: Columns (0,1,2,3,4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path, encoding='utf-8', on_bad_lines='skip', quoting=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully!\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3796431 entries, 0 to 3796430\n",
            "Data columns (total 7 columns):\n",
            " #   Column                   Dtype \n",
            "---  ------                   ----- \n",
            " 0   tweet_id                 object\n",
            " 1   author_id                object\n",
            " 2   inbound                  object\n",
            " 3   created_at               object\n",
            " 4   text                     object\n",
            " 5   response_tweet_id        object\n",
            " 6   in_response_to_tweet_id  object\n",
            "dtypes: object(7)\n",
            "memory usage: 202.8+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Filter only customer queries (inbound=True)\n",
        "customer_queries = df[df['inbound'] == True].copy()\n",
        "\n",
        "# Create query categories based on keyword matching\n",
        "def categorize_query(text):\n",
        "    text = text.lower()\n",
        "    if re.search(r'\\b(order|purchase|track|status|shipment|delivery)\\b', text):\n",
        "        return 'Order Status'\n",
        "    elif re.search(r'\\b(return|refund|exchange|cancel)\\b', text):\n",
        "        return 'Returns & Refunds'\n",
        "    elif re.search(r'\\b(product|specification|features|availability)\\b', text):\n",
        "        return 'Product Information'\n",
        "    elif re.search(r'\\b(account|login|password|email)\\b', text):\n",
        "        return 'Account Issues'\n",
        "    elif re.search(r'\\b(technical|bug|issue|crash|error)\\b', text):\n",
        "        return 'Technical Support'\n",
        "    else:\n",
        "        return 'Other'\n",
        "\n",
        "# Apply categorization\n",
        "customer_queries['category'] = customer_queries['text'].apply(categorize_query)\n",
        "\n",
        "# Clean the text\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'@\\w+', '', text)     # Remove mentions\n",
        "    text = re.sub(r'#\\w+', '', text)     # Remove hashtags\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
        "    text = text.lower().strip()\n",
        "    return text\n",
        "\n",
        "# Apply text cleaning\n",
        "customer_queries['clean_text'] = customer_queries['text'].apply(clean_text)\n",
        "\n",
        "# Display cleaned data\n",
        "print(customer_queries[['text', 'category', 'clean_text']].head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-g39Gfg-DMb",
        "outputId": "300a8932-d54b-4890-e4d0-c7ccbe39a4be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [text, category, clean_text]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure valid data for splitting\n",
        "if len(customer_queries) > 0:\n",
        "    X = customer_queries['clean_text']\n",
        "    y = customer_queries['category']\n",
        "\n",
        "    # Splitting the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # TF-IDF Vectorization\n",
        "    vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
        "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "    X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "    print(\"Training Set Size:\", X_train_tfidf.shape)\n",
        "    print(\"Testing Set Size:\", X_test_tfidf.shape)\n",
        "else:\n",
        "    print(\"No data available for training. Check the filtering process.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mykl73o5-XQt",
        "outputId": "4bf6fce2-c978-4f17-bc21-126ce24efd00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No data available for training. Check the filtering process.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the DataFrame is empty\n",
        "print(\"DataFrame Shape:\", customer_queries.shape)\n",
        "print(\"Sample rows:\")\n",
        "print(customer_queries.head())\n",
        "\n",
        "# Count non-empty rows\n",
        "print(\"Non-empty rows:\", len(customer_queries))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3iBH-uY-fSv",
        "outputId": "d5bc6e5c-b94b-4108-efa3-43e6c19a89ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame Shape: (0, 9)\n",
            "Sample rows:\n",
            "Empty DataFrame\n",
            "Columns: [tweet_id, author_id, inbound, created_at, text, response_tweet_id, in_response_to_tweet_id, category, clean_text]\n",
            "Index: []\n",
            "Non-empty rows: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure there is valid data\n",
        "if len(customer_queries) > 0:\n",
        "    X = customer_queries['clean_text']\n",
        "    y = customer_queries['category']\n",
        "\n",
        "    # Splitting the dataset into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # TF-IDF Vectorization\n",
        "    vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
        "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "    X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "    print(\"Training Set Size:\", X_train_tfidf.shape)\n",
        "    print(\"Testing Set Size:\", X_test_tfidf.shape)\n",
        "else:\n",
        "    print(\"No data available for training. Check the filtering process.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf-cALiU_FOP",
        "outputId": "d8152ed0-fda0-4e40-d584-e41f384232a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No data available for training. Check the filtering process.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display basic info again\n",
        "print(\"DataFrame Shape:\", customer_queries.shape)\n",
        "\n",
        "# Check for any missing columns\n",
        "print(\"\\nColumns in the dataset:\")\n",
        "print(customer_queries.columns)\n",
        "\n",
        "# Display non-empty rows count\n",
        "non_empty_rows = customer_queries.dropna(subset=['text']).shape[0]\n",
        "print(f\"\\nNon-empty rows (text only): {non_empty_rows}\")\n",
        "\n",
        "# Check for NaN values in 'category' and 'text'\n",
        "print(\"\\nMissing values:\")\n",
        "print(customer_queries.isna().sum())\n",
        "\n",
        "# Display a sample of rows, including any NaN categories\n",
        "print(\"\\nSample rows with NaN categories:\")\n",
        "print(customer_queries[customer_queries['category'].isna()].head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2OPz1kg_TbP",
        "outputId": "ee16db2b-e243-46d5-d2d2-48a75cdce7e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame Shape: (0, 9)\n",
            "\n",
            "Columns in the dataset:\n",
            "Index(['tweet_id', 'author_id', 'inbound', 'created_at', 'text',\n",
            "       'response_tweet_id', 'in_response_to_tweet_id', 'category',\n",
            "       'clean_text'],\n",
            "      dtype='object')\n",
            "\n",
            "Non-empty rows (text only): 0\n",
            "\n",
            "Missing values:\n",
            "tweet_id                   0\n",
            "author_id                  0\n",
            "inbound                    0\n",
            "created_at                 0\n",
            "text                       0\n",
            "response_tweet_id          0\n",
            "in_response_to_tweet_id    0\n",
            "category                   0\n",
            "clean_text                 0\n",
            "dtype: int64\n",
            "\n",
            "Sample rows with NaN categories:\n",
            "Empty DataFrame\n",
            "Columns: [tweet_id, author_id, inbound, created_at, text, response_tweet_id, in_response_to_tweet_id, category, clean_text]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the raw CSV with no filtering, handling bad lines\n",
        "raw_df = pd.read_csv(\"/content/twcs.csv\", encoding='latin1', on_bad_lines='skip')\n",
        "\n",
        "# Display the first few rows\n",
        "print(\"Raw DataFrame Shape:\", raw_df.shape)\n",
        "print(\"\\nSample Rows:\")\n",
        "print(raw_df.head())\n",
        "\n",
        "# Check for empty rows and missing values\n",
        "print(\"\\nEmpty Rows Count:\", raw_df.isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSfQG271_i7L",
        "outputId": "fd6df1e8-2a59-4a3e-9d07-6a665bf0a49b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw DataFrame Shape: (2811774, 7)\n",
            "\n",
            "Sample Rows:\n",
            "   tweet_id   author_id  inbound                      created_at  \\\n",
            "0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
            "1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
            "2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
            "3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
            "4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
            "\n",
            "                                                text response_tweet_id  \\\n",
            "0  @115712 I understand. I would like to assist y...                 2   \n",
            "1      @sprintcare and how do you propose we do that               NaN   \n",
            "2  @sprintcare I have sent several private messag...                 1   \n",
            "3  @115712 Please send us a Private Message so th...                 3   \n",
            "4                                 @sprintcare I did.                 4   \n",
            "\n",
            "   in_response_to_tweet_id  \n",
            "0                      3.0  \n",
            "1                      1.0  \n",
            "2                      4.0  \n",
            "3                      5.0  \n",
            "4                      6.0  \n",
            "\n",
            "Empty Rows Count: tweet_id                         0\n",
            "author_id                        0\n",
            "inbound                          0\n",
            "created_at                       0\n",
            "text                             0\n",
            "response_tweet_id          1040629\n",
            "in_response_to_tweet_id     794335\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns with high missing values\n",
        "df = raw_df.drop(['response_tweet_id', 'in_response_to_tweet_id'], axis=1)\n",
        "\n",
        "# Filter rows with valid 'text'\n",
        "df = df[df['text'].notnull() & (df['text'].str.strip() != '')]\n",
        "\n",
        "# Display dataset shape after cleaning\n",
        "print(\"Cleaned DataFrame Shape:\", df.shape)\n",
        "\n",
        "# Create sample category mapping based on keywords (basic classification)\n",
        "def categorize_text(text):\n",
        "    text = text.lower()\n",
        "    if 'bill' in text or 'charge' in text:\n",
        "        return 'billing'\n",
        "    elif 'network' in text or 'signal' in text:\n",
        "        return 'network_issue'\n",
        "    elif 'refund' in text or 'return' in text:\n",
        "        return 'refund_request'\n",
        "    elif 'thank' in text or 'appreciate' in text:\n",
        "        return 'feedback'\n",
        "    else:\n",
        "        return 'other'\n",
        "\n",
        "# Apply basic categorization\n",
        "df['category'] = df['text'].apply(categorize_text)\n",
        "\n",
        "# Display sample rows with categories\n",
        "print(\"\\nSample Rows with Categories:\")\n",
        "print(df[['text', 'category']].head())\n",
        "\n",
        "# Check distribution of categories\n",
        "print(\"\\nCategory Distribution:\")\n",
        "print(df['category'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TMwBRXc_sek",
        "outputId": "f5ea931c-4427-4f3d-c832-253c406d4c5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned DataFrame Shape: (2811774, 5)\n",
            "\n",
            "Sample Rows with Categories:\n",
            "                                                text category\n",
            "0  @115712 I understand. I would like to assist y...    other\n",
            "1      @sprintcare and how do you propose we do that    other\n",
            "2  @sprintcare I have sent several private messag...    other\n",
            "3  @115712 Please send us a Private Message so th...    other\n",
            "4                                 @sprintcare I did.    other\n",
            "\n",
            "Category Distribution:\n",
            "category\n",
            "other             2346817\n",
            "feedback           330048\n",
            "billing             57058\n",
            "refund_request      52753\n",
            "network_issue       25098\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model for training :"
      ],
      "metadata": {
        "id": "aytRdZbLAATn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Split the dataset into training and testing sets (80/20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['category'], test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))  # Using bigrams and unigrams\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Model Training\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Model Evaluation\n",
        "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4fFjszjAECr",
        "outputId": "53952fba-781e-4255-ee54-f498accdc6a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 0.9963937370522179\n",
            "\n",
            "Classification Report:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       billing       1.00      0.92      0.96     11288\n",
            "      feedback       1.00      0.99      0.99     65603\n",
            " network_issue       0.99      0.94      0.96      5099\n",
            "         other       1.00      1.00      1.00    469635\n",
            "refund_request       0.99      0.97      0.98     10730\n",
            "\n",
            "      accuracy                           1.00    562355\n",
            "     macro avg       0.99      0.96      0.98    562355\n",
            "  weighted avg       1.00      1.00      1.00    562355\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 10430     88     17    662     91]\n",
            " [     1  65135      0    467      0]\n",
            " [     0     50   4788    243     18]\n",
            " [     1      0     43 469576     15]\n",
            " [     0     91      0    241  10398]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model and TF-IDF vectorizer\n",
        "joblib.dump(nb_model, 'naive_bayes_model.pkl')\n",
        "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
        "print(\"Model and vectorizer saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "yF-hNau4AFSW",
        "outputId": "bebdbcd7-81e9-4942-d276-32731acfc59d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nb_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-517c284fa2c9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Save the model and TF-IDF vectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'naive_bayes_model.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tfidf_vectorizer.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model and vectorizer saved!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nb_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%who\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUKaVK8nBRuF",
        "outputId": "4e4a77ad-5dd6-49fd-da03-a049a480fe84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KaggleDatasetAdapter\t LogisticRegression\t TfidfVectorizer\t X\t X_test\t X_test_tfidf\t X_train\t X_train_tfidf\t accuracy_score\t \n",
            "categorize_query\t categorize_text\t classification_report\t clean_text\t confusion_matrix\t customer_queries\t dataset_url\t df\t file_path\t \n",
            "joblib\t kagglehub\t model\t non_empty_rows\t np\t pd\t raw_df\t re\t requests\t \n",
            "train_test_split\t vectorizer\t y\t y_pred\t y_test\t y_train\t \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model and the TF-IDF vectorizer\n",
        "joblib.dump(model, 'naive_bayes_model.pkl')\n",
        "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n",
        "print(\"Model and vectorizer saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcjx65_qBdqn",
        "outputId": "404bdda9-cb8b-4435-95bf-7e0b6f6f32d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and vectorizer saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Load the model and vectorizer\n",
        "model = joblib.load('naive_bayes_model.pkl')\n",
        "vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
        "\n",
        "# Sample prediction\n",
        "sample_query = [\"I want a refund for my recent order.\"]\n",
        "sample_tfidf = vectorizer.transform(sample_query)\n",
        "category = model.predict(sample_tfidf)\n",
        "print(\"Predicted Category:\", category[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IcsGsugBjGM",
        "outputId": "d27be5ab-61c2-440f-dc76-41a680e76b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Category: refund_request\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Flask joblib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMYpVwD1C2FP",
        "outputId": "f4627bc6-55d2-470b-c8bb-8725b4eb8522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the saved model and vectorizer\n",
        "model = joblib.load(\"model/naive_bayes_model.pkl\")\n",
        "vectorizer = joblib.load(\"model/tfidf_vectorizer.pkl\")\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"Customer Query Classification API\"\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    try:\n",
        "        data = request.get_json()\n",
        "        query = data.get('query')\n",
        "\n",
        "        if not query:\n",
        "            return jsonify({\"error\": \"No query provided\"}), 400\n",
        "\n",
        "        # Vectorize the input query\n",
        "        query_tfidf = vectorizer.transform([query])\n",
        "\n",
        "        # Make the prediction\n",
        "        prediction = model.predict(query_tfidf)[0]\n",
        "\n",
        "        # Return the predicted category\n",
        "        return jsonify({\"query\": query, \"category\": prediction})\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "cY4bPB4lC8Qu",
        "outputId": "708e3dd3-0dd6-4749-be75-90b19b446c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'model/naive_bayes_model.pkl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-47a164d7afe3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load the saved model and vectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model/naive_bayes_model.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model/tfidf_vectorizer.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model/naive_bayes_model.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the saved model and vectorizer\n",
        "model = joblib.load(\"model/naive_bayes_model.pkl\")\n",
        "vectorizer = joblib.load(\"model/tfidf_vectorizer.pkl\")\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"Customer Query Classification API\"\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    try:\n",
        "        data = request.get_json()\n",
        "        query = data.get('query')\n",
        "\n",
        "        if not query:\n",
        "            return jsonify({\"error\": \"No query provided\"}), 400\n",
        "\n",
        "        # Vectorize the input query\n",
        "        query_tfidf = vectorizer.transform([query])\n",
        "\n",
        "        # Make the prediction\n",
        "        prediction = model.predict(query_tfidf)[0]\n",
        "\n",
        "        # Return the predicted category\n",
        "        return jsonify({\"query\": query, \"category\": prediction})\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "id": "neq-C3pjC81O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "from pyngrok import ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the saved model and vectorizer\n",
        "model = joblib.load(\"/content/naive_bayes_model.pkl\")\n",
        "vectorizer = joblib.load(\"/content/tfidf_vectorizer.pkl\")\n",
        "\n",
        "# Start ngrok tunnel\n",
        "port = 5000\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(f\" Public URL: {public_url}\")\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"Customer Query Classification API\"\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    try:\n",
        "        data = request.get_json()\n",
        "        query = data.get('query')\n",
        "\n",
        "        if not query:\n",
        "            return jsonify({\"error\": \"No query provided\"}), 400\n",
        "\n",
        "        # Vectorize the input query\n",
        "        query_tfidf = vectorizer.transform([query])\n",
        "\n",
        "        # Make the prediction\n",
        "        prediction = model.predict(query_tfidf)[0]\n",
        "\n",
        "        # Return the predicted category\n",
        "        return jsonify({\"query\": query, \"category\": prediction})\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(port=port)\n"
      ],
      "metadata": {
        "id": "0CDj-COnDXJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n"
      ],
      "metadata": {
        "id": "DkWoyhjhcYEf",
        "outputId": "45e3b69a-7c42-4526-9911-cb2ce7f76e84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.3\n"
          ]
        }
      ]
    }
  ]
}